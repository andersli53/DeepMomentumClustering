{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSsUJSa9ZVnamx3FLc7Pqg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Mo2JJy9ebI64"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime, timedelta\n","from pandas.tseries.offsets import BDay\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import json\n","\n","import yfinance as yf\n","from tqdm import tqdm"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","path = '/content/drive/MyDrive/Colab Notebooks/Imperial MLDS/DeepTimeSeriesClustering'\n","os.chdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzs49JZIdPMi","executionInfo":{"status":"ok","timestamp":1755541566200,"user_tz":-480,"elapsed":16880,"user":{"displayName":"Anders Li","userId":"15399523505988166304"}},"outputId":"7a7c8180-422a-4383-9b36-78d50b60dc18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Import Config File"],"metadata":{"id":"DSl0dLlfHikn"}},{"cell_type":"code","source":["params_filename = \"params.json\"\n","params_path = os.path.join(path, params_filename)\n","\n","with open(params_path, 'r') as f:\n","  config = json.load(f)\n","\n","# Define key dates\n","cut_off_date = config['cut_off_date']\n","data_start = config['data_start']\n","strat_start = config['strat_start']\n","strat_end = config['strat_end']"],"metadata":{"id":"1osfXCBmGw2m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# S&P 500 Historical Constituents"],"metadata":{"id":"cUKZImQWHdGV"}},{"cell_type":"code","source":["# Import historical constituents\n","filename = \"s&p500_historical_constituents.csv\"\n","file_path = os.path.join(path, filename)\n","snp500_hist_cons = pd.read_csv(file_path, encoding='utf-8')\n","\n","# Historical constituent data preprocessing\n","snp500_hist_cons['tickers'] = snp500_hist_cons['tickers'].str.split(\",\")\n","snp500_hist_cons = snp500_hist_cons.explode(\"tickers\")\n","\n","# Get start and end date for each constituent\n","start_date = pd.DataFrame(snp500_hist_cons.groupby(\"tickers\")['date'].min()).rename(columns={'date': 'start_date'})\n","end_date = pd.DataFrame(snp500_hist_cons.groupby(\"tickers\")['date'].max()).rename(columns={'date': 'end_date'})\n","date_ranges = start_date.merge(end_date, left_index=True, right_index=True)\n","\n","# Filter date ranges\n","strat_mask = (date_ranges['start_date'] <= cut_off_date) & (date_ranges['end_date'] >= cut_off_date)\n","snp500_cons_cut_off = date_ranges[strat_mask]\n","snp500_cons_cut_off['strat_start'] = data_start\n","snp500_cons_cut_off['strat_end'] = strat_end\n","snp500_cons_cut_off = snp500_cons_cut_off.reset_index()"],"metadata":{"id":"SkIg-1dgbVPn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functions For Pricing Data Preprocessing"],"metadata":{"id":"NBnOoXs_IDxC"}},{"cell_type":"code","source":["# Get price from yfinance\n","def get_price(ticker, start, end, interval='1d'):\n","  try:\n","    data = yf.download(ticker, start, end, ignore_tz=True,\n","                       multi_level_index=False, progress=False,\n","                       auto_adjust=True, interval=interval)\n","    data.reset_index(inplace=True)\n","    data['Ticker'] = ticker\n","    data = data[['Ticker', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n","    return data\n","  except KeyError as e:\n","    print(ticker, f\"failed. {e}\")"],"metadata":{"id":"q7nKN0CLqJNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute RSI\n","def compute_rsi(df, rsi_window=\"14d\"):\n","  df_copy = df.copy()\n","  df_copy['delta'] = df_copy.groupby(\"Ticker\")['Close'].diff()\n","  df_copy['delta_gain'] = np.where(df_copy['delta'] > 0, df_copy['delta'], 0)\n","  df_copy['delta_loss'] = np.where(df_copy['delta'] < 0, -df_copy['delta'], 0)\n","  df_copy['delta_gain'] = df_copy['delta_gain'].fillna(0.0)\n","  df_copy['delta_loss'] = df_copy['delta_loss'].fillna(0.0)\n","  gain = df_copy.groupby(\"Ticker\").rolling(window=rsi_window, on=\"Date\")['delta_gain'].mean().reset_index().rename(columns={\"delta_gain\": \"gain\"})\n","  loss = df_copy.groupby(\"Ticker\").rolling(window=rsi_window, on=\"Date\")['delta_loss'].mean().reset_index().rename(columns={\"delta_loss\": \"loss\"})\n","  df_copy = df_copy.merge(gain, on=['Ticker', 'Date'], how='inner')\n","  df_copy = df_copy.merge(loss, on=['Ticker', 'Date'], how='inner')\n","  df_copy['rsi'] = 100. - (100. / (1 + df_copy['gain']/df_copy['loss']))\n","  return df_copy\n","\n","# Compute MACD\n","def compute_macd(df, short_window=\"12d\", long_window=\"26d\", signal_window=\"9d\"):\n","  df_copy = df.copy()\n","  # Ensure Date is datetime\n","  df_copy['Date'] = pd.to_datetime(df_copy['Date'])\n","\n","  # Group by Ticker and compute EMAs\n","  df_copy['short_ema'] = df_copy.groupby(\"Ticker\").apply(\n","      lambda x: x['Close'].ewm(halflife=short_window, times=pd.to_datetime(x['Date'])).mean(),\n","      include_groups=False\n","  ).reset_index(drop=True)\n","\n","  df_copy['long_ema'] = df_copy.groupby(\"Ticker\").apply(\n","      lambda x: x['Close'].ewm(halflife=long_window, times=pd.to_datetime(x['Date'])).mean(),\n","      include_groups=False\n","  ).reset_index(drop=True)\n","\n","  # Compute MACD line\n","  df_copy['macd'] = df_copy['short_ema'] - df_copy['long_ema']\n","\n","  # Compute Signal line\n","  df_copy['signal'] = df_copy.groupby(\"Ticker\").apply(\n","      lambda x: x['macd'].ewm(halflife=signal_window, times=pd.to_datetime(x['Date'])).mean(),\n","      include_groups=False\n","  ).reset_index(drop=True)\n","\n","  return df_copy\n","\n","# Data transformation\n","def data_transformer(df, window=\"20d\", rsi_window=\"14d\", short_window=\"12d\", long_window=\"26d\", signal_window=\"9d\"):\n","  df_copy = df.copy()\n","\n","  epsilon = 1e-10\n","  df_copy['r_open'] = np.log(df_copy['Open'].groupby(df_copy['Ticker']).pct_change().add(1 + epsilon))\n","  df_copy['r_high'] = np.log(df_copy['High'].groupby(df_copy['Ticker']).pct_change().add(1 + epsilon))\n","  df_copy['r_low'] = np.log(df_copy['Low'].groupby(df_copy['Ticker']).pct_change().add(1 + epsilon))\n","  df_copy['r_close'] = np.log(df_copy['Close'].groupby(df_copy['Ticker']).pct_change().add(1 + epsilon))\n","\n","  df_copy['log_volume'] = np.log(df_copy['Volume'])\n","  df_copy['log_volume'] = df_copy['log_volume'].replace(np.float64(\"-inf\"), 0.0)\n","  df_copy['Date'] = pd.to_datetime(df_copy['Date'])\n","\n","  rolling_mean = df_copy.groupby(\"Ticker\").rolling(window=window, on=\"Date\")[\"log_volume\"].mean().reset_index().rename(columns={\"log_volume\": \"rolling_mean\"})\n","  df_copy = df_copy.merge(rolling_mean, on=['Ticker', 'Date'], how='inner')\n","  df_copy['norm_log_volume'] = df_copy['log_volume'] / (df_copy['rolling_mean'] + epsilon)\n","\n","  rolling_sum = df_copy.groupby(\"Ticker\").rolling(window=window, on=\"Date\")[\"r_close\"].sum().reset_index().rename(columns={\"r_close\": \"r_sum\"})\n","  rolling_std = df_copy.groupby(\"Ticker\").rolling(window=window, on=\"Date\")[\"r_close\"].std().reset_index().rename(columns={\"r_close\": \"r_std\"})\n","  df_copy = df_copy.merge(rolling_sum, on=['Ticker', 'Date'], how='inner')\n","  df_copy = df_copy.merge(rolling_std, on=['Ticker', 'Date'], how='inner')\n","  df_copy['r_cum'] = df_copy['r_sum'] / (df_copy['r_std'] + epsilon)\n","\n","  df_copy = compute_rsi(df_copy, rsi_window=rsi_window)\n","  df_copy = compute_macd(df_copy, short_window=short_window, long_window=long_window, signal_window=signal_window)\n","  df_copy = df_copy.fillna(0.0)\n","  return df_copy"],"metadata":{"id":"xJpz0MdQC4Gv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"LlVD6Vi9IRH3"}},{"cell_type":"code","source":["filename = \"snp500_hist_cluster.csv\"\n","hist_price_path = os.path.join(path, filename)\n","\n","if not os.path.isfile(hist_price_path):\n","  print(\"Downloading data...\\n\")\n","  snp500_cons_hist_data = snp500_cons_cut_off.apply(\n","      lambda df:\n","      get_price(ticker=df.tickers,\n","                start=df.strat_start,\n","                end=df.strat_end,\n","                interval='1d'),\n","      axis=1\n","  )\n","  snp500_hist = pd.concat(snp500_cons_hist_data.values)\n","\n","  rolling_window = '20d'\n","  rsi_window = '14d'\n","  short_window = '12d'\n","  long_window = '26d'\n","  signal_window = '9d'\n","\n","  snp500_hist_transformed = data_transformer(\n","      snp500_hist,\n","      window=rolling_window,\n","      rsi_window=rsi_window,\n","      short_window=short_window,\n","      long_window=long_window,\n","      signal_window=signal_window\n","  )\n","\n","  snp500_hist_transformed = snp500_hist_transformed[(snp500_hist_transformed['Date'] >= strat_start) & (snp500_hist_transformed['Date'] <= strat_end)].reset_index(drop=True)\n","\n","  snp500_hist_transformed.to_csv(hist_price_path, index=False)\n","  print(f\"Exported as {filename}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fUqZcYrtOkR","executionInfo":{"status":"ok","timestamp":1755541918075,"user_tz":-480,"elapsed":111530,"user":{"displayName":"Anders Li","userId":"15399523505988166304"}},"outputId":"685f24ad-a827-4b00-cb27-b419c9149ba8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data...\n","\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:yfinance:\n","1 Failed download:\n","ERROR:yfinance:['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2024-04-01 -> 2025-04-30)')\n","ERROR:yfinance:\n","1 Failed download:\n","ERROR:yfinance:['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"]},{"output_type":"stream","name":"stdout","text":["Exported as snp500_hist_cluster.csv\n"]}]},{"cell_type":"code","source":["snp500_hist_transformed = pd.read_csv(hist_price_path, encoding='utf-8')\n","features = [\"r_close\", \"norm_log_volume\", \"rsi\", \"macd\", \"signal\"]\n","n_features = len(features)\n","tickers = snp500_hist_transformed['Ticker'].unique()\n","time_steps = len(snp500_hist_transformed['Date'].unique())\n","n_stocks = len(tickers)\n","\n","print(f\"\"\"\n","Input features: {features}\n","Number of input features: {n_features}\n","Number of tickers: {n_stocks}\n","Number of time_steps: {time_steps}\n","\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_01oAHvcAVgE","executionInfo":{"status":"ok","timestamp":1755541928952,"user_tz":-480,"elapsed":1190,"user":{"displayName":"Anders Li","userId":"15399523505988166304"}},"outputId":"e8d52c34-47c6-47b7-f594-65570dadb840"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input features: ['r_close', 'norm_log_volume', 'rsi', 'macd', 'signal']\n","Number of input features: 5\n","Number of tickers: 500\n","Number of time_steps: 249\n","\n"]}]},{"cell_type":"markdown","source":["# Create Dataset"],"metadata":{"id":"AOZrOWxaJ_xE"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Scale features\n","scaler = StandardScaler()\n","snp500_hist_transformed[features] = scaler.fit_transform(snp500_hist_transformed[features])"],"metadata":{"id":"_H8ugyZxKAky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","data = []\n","real_data_metadata = []\n","batch_size = config['batch_size']\n","for ticker in tickers:\n","  stock_data = snp500_hist_transformed[snp500_hist_transformed['Ticker'] == ticker].sort_values('Date')\n","  if len(stock_data) != time_steps:\n","      print(f\"{ticker} has {len(stock_data)} time steps. Expected {time_steps}\")\n","      sequence = stock_data[features].values\n","      # Pad data with 0 if fewer than time_steps\n","      if len(sequence) < time_steps:\n","          padding = np.zeros((time_steps - len(sequence), n_features))\n","          sequence = np.vstack([sequence, padding])\n","      # Truncate data if more than time_steps\n","      elif len(sequence) > time_steps:\n","          sequence = sequence[:time_steps]\n","  else:\n","      sequence = stock_data[features].values\n","  data.append(sequence)\n","  real_data_metadata.append({\n","      'Ticker': ticker,\n","      'StartDate': stock_data['Date'].iloc[0],\n","      'EndDate': stock_data['Date'].iloc[-1]\n","  })\n","\n","data = np.array(data)\n","print(f\"Data shape: {data.shape}\")\n","\n","# Convert to tensors\n","data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n","dataset = tf.data.Dataset.from_tensor_slices(data_tensor).batch(batch_size, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n","print(f\"Number of batches: {len(list(dataset))}\")\n","\n","real_data_metadata = pd.DataFrame(real_data_metadata)\n","print(f\"Metadata shape: {real_data_metadata.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPkWF8d7KFNK","executionInfo":{"status":"ok","timestamp":1755541945061,"user_tz":-480,"elapsed":12390,"user":{"displayName":"Anders Li","userId":"15399523505988166304"}},"outputId":"ecdc789b-91b8-4de0-b0c2-fb4c4d5961bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data shape: (500, 249, 5)\n","Number of batches: 32\n","Metadata shape: (500, 3)\n"]}]}]}